{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home-nfs2/local/VANDERBILT/kanakap/py38-venv/lib/python3.8/site-packages/tqdm/auto.py:22: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import torch\n",
    "from src.utils import *\n",
    "from src.model_all import *\n",
    "from scipy.ndimage import gaussian_filter\n",
    "from nilearn.image import resample_img"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Resample data\n",
    "input_file = '/nfs/masi/kanakap/projects/DeepN4/data/IXI015-HH-1258-T1.nii.gz'\n",
    "output_file = '/nfs/masi/kanakap/projects/DeepN4/data/resampled_IXI015-HH-1258-T1.nii.gz'\n",
    "x_res, y_res, z_res = 2, 2, 2\n",
    "os.system('mri_convert \\\"{}\\\" \\\"{}\\\" -vs {} {} {} -rt cubic'.format(input_file, output_file, x_res, y_res, z_res))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load( subj ):\n",
    "\n",
    "    input_data = nib.load(subj).get_fdata()\n",
    "    input_data, [lx,lX,ly,lY,lz,lZ,rx,rX,ry,rY,rz,rZ] = pad(input_data, 128)\n",
    "    in_max = np.percentile(input_data[np.nonzero(input_data)], 99.99)\n",
    "    input_data = normalize_img(input_data, in_max, 0, 1, 0)\n",
    "    input_data = np.squeeze(input_data)\n",
    "    input_vols = np.zeros((1,1, 128, 128, 128))\n",
    "    input_vols[0,0,:,:,:] = input_data\n",
    "\n",
    "    return torch.from_numpy(input_vols).float(), lx,lX,ly,lY,lz,lZ,rx,rX,ry,rY,rz,rZ, in_max"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Inference function\n",
    "def pred_model( input_path, checkpoint_file ):\n",
    "    use_cuda = torch.cuda.is_available()\n",
    "    torch.manual_seed(1)\n",
    "    device = torch.device(\"cuda\" if use_cuda else \"cpu\")\n",
    "    kwargs = {'num_workers': 10, 'pin_memory': True} if use_cuda else {}\n",
    "\n",
    "    # Get model checkpoint\n",
    "    model = Synbo_UNet3D(1, 1).to(device)\n",
    "    model = load_model(model, checkpoint_file)\n",
    "    model.eval()\n",
    "    in_features, lx,lX,ly,lY,lz,lZ,rx,rX,ry,rY,rz,rZ, in_max = load(input_path)\n",
    "\n",
    "    in_features = in_features.to(device)\n",
    "    logfield = model(in_features, device)\n",
    "    field = torch.exp(logfield)\n",
    "\n",
    "    field = field.cpu()\n",
    "    input_data = in_features.cpu()  \n",
    "\n",
    "    # Reshape\n",
    "    field = field.squeeze()\n",
    "    field_ny = field.detach().numpy()\n",
    "    input_data = input_data.squeeze()\n",
    "\n",
    "    org_data = nib.load(input_path).get_fdata()\n",
    "    final_field = np.zeros([org_data.shape[0], org_data.shape[1], org_data.shape[2]])\n",
    "    final_field[rx:rX,ry:rY,rz:rZ] = field_ny[lx:lX,ly:lY,lz:lZ]\n",
    "\n",
    "    final_input = np.zeros([org_data.shape[0], org_data.shape[1], org_data.shape[2]])\n",
    "    final_input[rx:rX,ry:rY,rz:rZ] = input_data[lx:lX,ly:lY,lz:lZ]\n",
    "\n",
    "    # Compute corrected image\n",
    "    final_field = gaussian_filter(final_field, sigma=3)\n",
    "    final_corrected = final_input / final_field\n",
    "    final_corrected = unnormalize_img(final_corrected, in_max, 0, 1, 0)\n",
    "\n",
    "    return final_corrected, final_field"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run inference function # Download the checkpointfile from https://drive.google.com/drive/folders/1mdBsV0kHRRV_Alu1QJrTT7N0GGNJDuiu?usp=sharing \n",
    "# pred_model(gpu_no, test_file, checkpoint_file, pred_dir, filter_type) ADD FILTER TYPE option\n",
    "final_corrected, final_field = pred_model(output_file, checkpoint_file='/nfs/masi/kanakap/projects/DeepN4/src/trained_model_Synbo_UNet3D/checkpoint_epoch_264')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save\n",
    "ref = nib.load(output_file)\n",
    "nii = nib.Nifti1Image(final_corrected, affine=ref.affine, header=ref.header)\n",
    "nib.save(nii, '/nfs/masi/kanakap/projects/DeepN4/data/corrected_IXI015-HH-1258-T1.nii.gz')\n",
    "\n",
    "nii = nib.Nifti1Image(final_field, affine=ref.affine, header=ref.header)\n",
    "nib.save(nii, '/nfs/masi/kanakap/projects/DeepN4/data/predicted_field_IXI015-HH-1258-T1.nii.gz')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Resample back to orginal resolution \n",
    "ref = nib.load(input_file)\n",
    "output_img = resample_img(nib.Nifti1Image(final_corrected, nib.load(output_file).affine), target_affine=ref.affine, target_shape=ref.shape)\n",
    "nib.save(output_img, '/nfs/masi/kanakap/projects/DeepN4/data/corrected_upsampled_IXI015-HH-1258-T1.nii.gz')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "py38-venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "7fa644da4117da0e44340091776451c590b7b6ff2c315e392394e62db01e6c76"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
